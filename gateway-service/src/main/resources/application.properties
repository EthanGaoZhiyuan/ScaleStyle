spring.application.name=gateway-service

# Tomcat thread pool for handling concurrent requests
server.tomcat.threads.max=200
server.tomcat.threads.min-spare=50
server.tomcat.max-connections=8192
server.tomcat.accept-count=100

# Phase 2 default: call Ray Serve via HTTP
inference.base-url=${INFERENCE_BASE_URL:http://localhost:8000}

# Force simple HTTP client to avoid HTTP/2 compatibility issues with Ray Serve
spring.http.client.factory=simple

# HTTP Client connection pool for inference service
inference.http.max-conn-total=200
inference.http.max-conn-per-route=50
inference.http.connect-timeout=1000
# Phase2 v2.3: 300ms timeout balances latency vs false fallback rate
inference.http.read-timeout=250

# Redis connection
spring.data.redis.host=${REDIS_HOST:localhost}
spring.data.redis.port=${REDIS_PORT:6379}
spring.data.redis.timeout=2000ms
spring.data.redis.lettuce.pool.max-active=8
spring.data.redis.lettuce.pool.max-idle=8
spring.data.redis.lettuce.pool.min-idle=2

# Two-tier cache configuration
cache.local.max-size=${CACHE_LOCAL_MAX_SIZE:1000}
cache.local.ttl-minutes=${CACHE_LOCAL_TTL_MINUTES:5}

# Actuator endpoints - expose prometheus metrics
management.endpoints.web.exposure.include=health,info,prometheus
management.endpoint.prometheus.enabled=true
management.metrics.export.prometheus.enabled=true

# Enable Kubernetes health probes (readiness/liveness)
management.endpoint.health.probes.enabled=true
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true

# Resilience4j configuration for Ray inference service
# TimeLimiter config removed to match code (uses HTTP client 450ms timeout + sync wrapper 800ms timeout)
# CircuitBreaker: Open circuit if 50% of recent calls fail
resilience4j.circuitbreaker.instances.ray.sliding-window-type=COUNT_BASED
resilience4j.circuitbreaker.instances.ray.sliding-window-size=50
resilience4j.circuitbreaker.instances.ray.minimum-number-of-calls=5
resilience4j.circuitbreaker.instances.ray.failure-rate-threshold=50
resilience4j.circuitbreaker.instances.ray.wait-duration-in-open-state=10s
resilience4j.circuitbreaker.instances.ray.permitted-number-of-calls-in-half-open-state=5
# Record all common HTTP and timeout exceptions (don't wrap them!)
resilience4j.circuitbreaker.instances.ray.record-exceptions=java.util.concurrent.TimeoutException,org.springframework.web.client.ResourceAccessException,org.springframework.web.client.HttpServerErrorException,org.springframework.web.client.HttpClientErrorException,java.lang.RuntimeException

# Enable Resilience4j metrics
management.metrics.tags.application=${spring.application.name}
resilience4j.circuitbreaker.instances.ray.register-health-indicator=true

# OpenTelemetry distributed tracing configuration (AI Infra interview requirement)
# Enable trace propagation to inference-service for end-to-end observability
otel.service.name=gateway-service
otel.traces.exporter=otlp
otel.exporter.otlp.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT:http://jaeger:4317}
otel.exporter.otlp.protocol=grpc
otel.metrics.exporter=none
otel.logs.exporter=none
# Propagate trace context via HTTP headers (traceparent, tracestate)
otel.propagators=tracecontext,baggage