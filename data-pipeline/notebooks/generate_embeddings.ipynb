{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import files, drive\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "A-_kb8u1waEe"
      },
      "id": "A-_kb8u1waEe",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "COMPETITION_NAME = \"h-and-m-personalized-fashion-recommendations\"\n",
        "# This is where we want the data to be available for our Spark code\n",
        "LOCAL_DATA_DIR = Path(\"/content/hm_data\")\n",
        "\n",
        "# This is where the persistent data lives in your Google Drive\n",
        "# NOTE: Ensure this path matches where you saved it last time!\n",
        "DRIVE_MOUNT_POINT = \"/content/drive\"\n",
        "DRIVE_PROJECT_PATH = Path(DRIVE_MOUNT_POINT) / \"MyDrive/ScaleStyle_Project/data\"\n",
        "# --- Configuration ---\n",
        "COMPETITION_NAME = \"h-and-m-personalized-fashion-recommendations\"\n",
        "# This is where we want the data to be available for our Spark code\n",
        "LOCAL_DATA_DIR = Path(\"/content/hm_data\")\n",
        "\n",
        "# This is where the persistent data lives in your Google Drive\n",
        "# NOTE: Ensure this path matches where you saved it last time!\n",
        "DRIVE_MOUNT_POINT = \"/content/drive\"\n",
        "DRIVE_PROJECT_PATH = Path(DRIVE_MOUNT_POINT) / \"MyDrive/ScaleStyle_Project/data\"\n",
        "ZIP_FILE_PATH = DRIVE_PROJECT_PATH / f\"{COMPETITION_NAME}.zip\""
      ],
      "metadata": {
        "id": "AzB0cnAwwl4b"
      },
      "id": "AzB0cnAwwl4b",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_data_from_drive():\n",
        "    \"\"\"\n",
        "    Mounts Google Drive and prepares the dataset.\n",
        "    1. Mounts Drive.\n",
        "    2. Checks if the ZIP file exists in Drive.\n",
        "    3. Extracts CSVs to the local Colab environment for fast access.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Mount Google Drive\n",
        "    if not os.path.exists(DRIVE_MOUNT_POINT):\n",
        "        print(\"ğŸ”¹ Mounting Google Drive...\")\n",
        "        drive.mount(DRIVE_MOUNT_POINT)\n",
        "    else:\n",
        "        print(\"âœ… Google Drive is already mounted.\")\n",
        "\n",
        "    # 2. Check for the dataset in Drive\n",
        "    if not ZIP_FILE_PATH.exists():\n",
        "        print(f\"âŒ Error: Dataset not found at {ZIP_FILE_PATH}\")\n",
        "        print(\"   Did you save it to a different folder last time?\")\n",
        "        print(\"   If this is a fresh start, you may need to run the download script once.\")\n",
        "        return\n",
        "\n",
        "    print(f\"âœ… Found cached dataset in Drive: {ZIP_FILE_PATH}\")\n",
        "\n",
        "    # 3. Extract to local environment (Faster IO than reading from Drive directly)\n",
        "    # We only extract if the target directory is empty or missing\n",
        "    if not LOCAL_DATA_DIR.exists():\n",
        "        print(\"ğŸ”¹ Extracting data to local Colab environment (this improves speed)...\")\n",
        "        LOCAL_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Unzip command is faster than Python zipfile\n",
        "        zip_source = str(ZIP_FILE_PATH)\n",
        "        target_dir = str(LOCAL_DATA_DIR)\n",
        "\n",
        "        # Extract specific CSVs to save space/time\n",
        "        !unzip -q -o \"{zip_source}\" \"articles.csv\" \"customers.csv\" \"transactions_train.csv\" -d \"{target_dir}\"\n",
        "\n",
        "        print(f\"âœ… Extraction complete! Data is ready at: {LOCAL_DATA_DIR}\")\n",
        "    else:\n",
        "        print(f\"âœ… Data already extracted at {LOCAL_DATA_DIR}. Skipping extraction.\")\n",
        "\n",
        "    print(f\"ğŸ“‚ Available files: {os.listdir(LOCAL_DATA_DIR)}\")\n",
        "\n",
        "\n",
        "# --- Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    setup_data_from_drive()"
      ],
      "metadata": {
        "id": "5qfXgZolxbJ3",
        "outputId": "ae986657-2c26-4d87-abd2-11c7712badd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5qfXgZolxbJ3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "âœ… Found cached dataset in Drive: /content/drive/MyDrive/ScaleStyle_Project/data/h-and-m-personalized-fashion-recommendations.zip\n",
            "ğŸ”¹ Extracting data to local Colab environment (this improves speed)...\n",
            "âœ… Extraction complete! Data is ready at: /content/hm_data\n",
            "ğŸ“‚ Available files: ['customers.csv', 'transactions_train.csv', 'articles.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# 1. Securely retrieve Token (will not be displayed on screen)\n",
        "try:\n",
        "    token = userdata.get(\"GITHUB_TOKEN\")\n",
        "    print(\"âœ… Token retrieved successfully\")\n",
        "except Exception:\n",
        "    print(\"âŒ Token not found. Please check the Secrets panel settings on the left\")\n",
        "\n",
        "# 2. Configure repository information\n",
        "username = \"EthanGaoZhiyuan\"\n",
        "repo = \"ScaleStyle\"\n",
        "\n",
        "# 3. Construct HTTPS URL with Token (Token used for authentication)\n",
        "# Format: https://token@github.com/username/repo.git\n",
        "clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n",
        "\n",
        "# 4. Execute clone command\n",
        "# Use the -b flag to directly clone a specific branch\n",
        "branch = \"feat/phase2-embedding\"\n",
        "!git clone -b {branch} {clone_url}\n",
        "\n",
        "# 5. Verification\n",
        "if os.path.exists(repo):\n",
        "    print(f\"\\nğŸ‰ Code downloaded to: {repo}\")\n",
        "    !ls {repo}\n",
        "else:\n",
        "    print(\"\\nâŒ Clone failed. Please check Token permissions or repository existence\")"
      ],
      "metadata": {
        "id": "mR-06AW1xbrJ",
        "outputId": "3af7b031-67c4-4896-de68-6e4b38e5aa1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mR-06AW1xbrJ",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Token retrieved successfully\n",
            "Cloning into 'ScaleStyle'...\n",
            "remote: Enumerating objects: 120, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 120 (delta 22), reused 104 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (120/120), 843.48 KiB | 20.57 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "\n",
            "ğŸ‰ Code downloaded to: ScaleStyle\n",
            "data-pipeline\t    docs\t     inference-service\tREADME.md\n",
            "docker-compose.yml  gateway-service  infrastructure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# 1. Change directory to the data-pipeline folder to access requirements.txt\n",
        "# This ensures pip installs the exact versions specified in your repo.\n",
        "repo_path = \"/content/ScaleStyle/data-pipeline\"\n",
        "os.chdir(repo_path)\n",
        "\n",
        "print(f\"ğŸ“‚ Current Working Directory: {os.getcwd()}\")\n",
        "\n",
        "# 2. Install dependencies\n",
        "# Using -q to keep the output clean.\n",
        "print(\"â¬‡ï¸ Installing dependencies from requirements.txt...\")\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# 3. Add the project root to system path\n",
        "# This allows Python to recognize 'src' as a module so we can do:\n",
        "# \"from src.feature_engineering import ...\"\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)\n",
        "    print(f\"âœ… Added {repo_path} to system path.\")\n",
        "\n",
        "print(\"âœ… Environment setup complete.\")"
      ],
      "metadata": {
        "id": "V-odJ1owx6Mx",
        "outputId": "c61bca92-d0cf-4e1f-d5c0-8f0e55dd6138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "V-odJ1owx6Mx",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“‚ Current Working Directory: /content/ScaleStyle/data-pipeline\n",
            "â¬‡ï¸ Installing dependencies from requirements.txt...\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.4/86.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.3/72.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.3/87.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m140.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.12.0 which is incompatible.\n",
            "rasterio 1.5.0 requires click!=8.2.*,>=4.0, but you have click 8.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Added /content/ScaleStyle/data-pipeline to system path.\n",
            "âœ… Environment setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENERATE EMBEDDINGS WITH BAAI/BGE-LARGE (INDUSTRIAL STANDARD)\n",
        "\n",
        "**MODEL SELECTION RATIONALE:**\n",
        "I switched to **\"BAAI/bge-large-en-v1.5\"** for the following reasons, targeting a more production-ready architecture:\n",
        "\n",
        "1.  **Industrial Standard (Efficiency vs. Performance)**: Unlike the 7B parameter Qwen2, BGE-Large has only **~335M parameters**. This represents the \"Gold Standard\" in the industry, allowing for ultra-low latency inference while maintaining top-tier retrieval quality.\n",
        "2.  **MTEB Leaderboard**: It consistently ranks high on the Massive Text Embedding Benchmark (MTEB), specifically for English retrieval tasks.\n",
        "3.  **Encoder Architecture (BERT-based)**: This uses a standard BERT-like architecture with a **512 token limit**, which is sufficient for product names and descriptions. It uses `[CLS]` pooling, which is structurally more suitable for vector search than Decoder-based LLMs.\n",
        "4.  **Hardware Optimization**: Due to its smaller size, we can significantly increase the **Batch Size (e.g., to 256)**, making the data processing pipeline 10x faster than before."
      ],
      "metadata": {
        "id": "84_TKIas3B4g"
      },
      "id": "84_TKIas3B4g"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "CJwl69l36RpA",
        "outputId": "3b624704-dd55-415b-827c-0a0946c8102b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CJwl69l36RpA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
        "BATCH_SIZE = 256\n",
        "MAX_LENGTH = 512\n",
        "\n",
        "# Input/Output Paths (Google Drive)\n",
        "INPUT_PATH = \"/content/drive/MyDrive/ScaleStyle_Project/data/processed/articles_parquet\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/ScaleStyle_Project/data/processed/article_embeddings_bge.parquet\"\n",
        "\n",
        "# def last_token_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "#     \"\"\"\n",
        "#     Extracts the embedding from the last token.\n",
        "#     For Causal LLMs (like Qwen) used as embedding models,\n",
        "#     pooling the last token (EOS) is the standard practice, unlike BERT which uses [CLS].\n",
        "#     \"\"\"\n",
        "#     left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
        "#     if left_padding:\n",
        "#         return last_hidden_states[:, -1]\n",
        "#     else:\n",
        "#         sequence_lengths = attention_mask.sum(dim=1) - 1\n",
        "#         batch_size = last_hidden_states.shape[0]\n",
        "#         # Gather the hidden state corresponding to the last real token\n",
        "#         return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
        "\n",
        "def cls_pooling(model_output):\n",
        "    \"\"\"\n",
        "    BGE/BERT Standard Pooling: Take the first token ([CLS])\n",
        "    \"\"\"\n",
        "    return model_output.last_hidden_state[:, 0]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Initializing SOTA model: {MODEL_NAME} on GPU...\")\n",
        "\n",
        "    # 1. Load Model & Tokenizer\n",
        "    # Note: 'trust_remote_code=True' is strictly required for Qwen2 custom architecture.\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "    model = AutoModel.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        trust_remote_code=False,\n",
        "        torch_dtype=torch.float16,  # Use FP16 to save VRAM and accelerate on A100\n",
        "        device_map=\"cuda\"\n",
        "    )\n",
        "\n",
        "    # 2. Load Data\n",
        "    print(f\"Reading article data from: {INPUT_PATH}\")\n",
        "    df_articles = pd.read_parquet(INPUT_PATH)\n",
        "\n",
        "    # 3. Construct Input Text\n",
        "    # Since I'm embedding documents (products), I use the raw text.\n",
        "    # Instruction prompts (e.g., \"Given a query...\") are only needed during the retrieval phase.\n",
        "\n",
        "    # Preprocessing\n",
        "    df_articles['prod_name'] = df_articles['prod_name'].fillna(\"Unknown Product\")\n",
        "    df_articles['detail_desc'] = df_articles['detail_desc'].fillna(\"\")\n",
        "    df_articles['colour_group_name'] = df_articles['colour_group_name'].fillna(\"\")\n",
        "\n",
        "    # Concatenate fields to form a rich semantic representation\n",
        "    raw_texts = (\n",
        "        \"Product: \" + df_articles['prod_name'] + \". \" +\n",
        "        \"Description: \" + df_articles['detail_desc'] + \". \" +\n",
        "        \"Attributes: \" + df_articles['colour_group_name']\n",
        "    ).tolist()\n",
        "\n",
        "    print(f\"Total items to process: {len(raw_texts)}\")\n",
        "\n",
        "    # 4. Batch Inference Loop\n",
        "    all_embeddings = []\n",
        "\n",
        "    print(\"Start Batch Inference with Qwen2...\")\n",
        "    for i in tqdm(range(0, len(raw_texts), BATCH_SIZE)):\n",
        "        batch_texts = raw_texts[i : i + BATCH_SIZE]\n",
        "\n",
        "        # Tokenize inputs\n",
        "        batch_dict = tokenizer(\n",
        "            batch_texts,\n",
        "            max_length=MAX_LENGTH,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch_dict)\n",
        "\n",
        "            # Extracting\n",
        "            embeddings = cls_pooling(outputs)\n",
        "\n",
        "            # Normalizing\n",
        "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
        "\n",
        "            # Move to CPU to save GPU memory\n",
        "            all_embeddings.append(embeddings.float().cpu().numpy())\n",
        "\n",
        "    # 5. Save Results\n",
        "    final_embeddings = np.concatenate(all_embeddings, axis=0)\n",
        "\n",
        "    # Save as a list column in the DataFrame\n",
        "    df_articles['embedding'] = list(final_embeddings)\n",
        "\n",
        "    # Keep only ID and Embedding columns for Milvus ingestion\n",
        "    output_df = df_articles[['article_id', 'embedding']]\n",
        "    output_df.to_parquet(OUTPUT_PATH)\n",
        "\n",
        "    print(f\"Embeddings saved to: {OUTPUT_PATH}\")\n",
        "    print(f\"CRITICAL NOTE: The vector dimension is {final_embeddings.shape[1]}.\")\n",
        "    print(f\"(Please ensure your Milvus Collection is created with dim={final_embeddings.shape[1]})\")"
      ],
      "metadata": {
        "id": "mkCKCjwNyWiq",
        "outputId": "e2bbee62-a18d-45d3-9d52-4559dedf61b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "945e7564ce2d43909f83192d642a3534",
            "f16b873f40d84cfaa6246b7ffcd0d437",
            "8f4832abe8f947cf8c7564761cc6706d",
            "95c5ff4d3fa14f0eb0ee48f8cef3af2c",
            "745f728d65584bcab338ee7a639aac26",
            "26c2e6f375de481280e3cc8f6ac8e756",
            "70f254fdfe3f4bf291cf4deec16d4d17",
            "aad7e881b1c14d1db9eddea1bd91225b",
            "e05bdbff14204e0b86d2978b4e33b633",
            "1f2a34170bb3421eabf6e60437c08683",
            "ba11700b77f147e9aa29fae1a269096c",
            "7a7cd151f337405e9fc1c3ea979d784c",
            "89b6c399515f440bbed54f998b510e2d",
            "e75716dbbcea4140a7c1b5d48b26e534",
            "e68b805c9902403e9ca1bdbfe7a34484",
            "437457e1893349d3a999f955a5669cb9",
            "7fec2bea408e4cf0afedc6f4c43376a9",
            "8866f462006740d2a8070a9eee4410d7",
            "cccda5ea23234b5bb5f33c7adb35472e",
            "dfdff5f6dd0b4363a0f064f90d39fd62",
            "b2b304e6babd4803b9c3fba31a317917",
            "5101497d08e94e8db3402210bff5d070"
          ]
        }
      },
      "id": "mkCKCjwNyWiq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing SOTA model: BAAI/bge-large-en-v1.5 on GPU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "945e7564ce2d43909f83192d642a3534"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading article data from: /content/drive/MyDrive/ScaleStyle_Project/data/processed/articles_parquet\n",
            "Total items to process: 105126\n",
            "Start Batch Inference with Qwen2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/411 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a7cd151f337405e9fc1c3ea979d784c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings saved to: /content/drive/MyDrive/ScaleStyle_Project/data/processed/article_embeddings_bge.parquet\n",
            "CRITICAL NOTE: The vector dimension is 1024.\n",
            "(Please ensure your Milvus Collection is created with dim=1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3b4-WVG5blA"
      },
      "id": "k3b4-WVG5blA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "945e7564ce2d43909f83192d642a3534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f16b873f40d84cfaa6246b7ffcd0d437",
              "IPY_MODEL_8f4832abe8f947cf8c7564761cc6706d",
              "IPY_MODEL_95c5ff4d3fa14f0eb0ee48f8cef3af2c"
            ],
            "layout": "IPY_MODEL_745f728d65584bcab338ee7a639aac26"
          }
        },
        "f16b873f40d84cfaa6246b7ffcd0d437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26c2e6f375de481280e3cc8f6ac8e756",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70f254fdfe3f4bf291cf4deec16d4d17",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "8f4832abe8f947cf8c7564761cc6706d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aad7e881b1c14d1db9eddea1bd91225b",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e05bdbff14204e0b86d2978b4e33b633",
            "value": 1340616616
          }
        },
        "95c5ff4d3fa14f0eb0ee48f8cef3af2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f2a34170bb3421eabf6e60437c08683",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ba11700b77f147e9aa29fae1a269096c",
            "value": "â€‡1.34G/1.34Gâ€‡[00:02&lt;00:00,â€‡1.09GB/s]"
          }
        },
        "745f728d65584bcab338ee7a639aac26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c2e6f375de481280e3cc8f6ac8e756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f254fdfe3f4bf291cf4deec16d4d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aad7e881b1c14d1db9eddea1bd91225b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05bdbff14204e0b86d2978b4e33b633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f2a34170bb3421eabf6e60437c08683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba11700b77f147e9aa29fae1a269096c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a7cd151f337405e9fc1c3ea979d784c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89b6c399515f440bbed54f998b510e2d",
              "IPY_MODEL_e75716dbbcea4140a7c1b5d48b26e534",
              "IPY_MODEL_e68b805c9902403e9ca1bdbfe7a34484"
            ],
            "layout": "IPY_MODEL_437457e1893349d3a999f955a5669cb9"
          }
        },
        "89b6c399515f440bbed54f998b510e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fec2bea408e4cf0afedc6f4c43376a9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8866f462006740d2a8070a9eee4410d7",
            "value": "100%"
          }
        },
        "e75716dbbcea4140a7c1b5d48b26e534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cccda5ea23234b5bb5f33c7adb35472e",
            "max": 411,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfdff5f6dd0b4363a0f064f90d39fd62",
            "value": 411
          }
        },
        "e68b805c9902403e9ca1bdbfe7a34484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2b304e6babd4803b9c3fba31a317917",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5101497d08e94e8db3402210bff5d070",
            "value": "â€‡411/411â€‡[00:57&lt;00:00,â€‡â€‡7.54it/s]"
          }
        },
        "437457e1893349d3a999f955a5669cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fec2bea408e4cf0afedc6f4c43376a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8866f462006740d2a8070a9eee4410d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cccda5ea23234b5bb5f33c7adb35472e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfdff5f6dd0b4363a0f064f90d39fd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2b304e6babd4803b9c3fba31a317917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5101497d08e94e8db3402210bff5d070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}