{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "A-_kb8u1waEe",
   "metadata": {
    "id": "A-_kb8u1waEe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from google.colab import files, drive\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "AzB0cnAwwl4b",
   "metadata": {
    "id": "AzB0cnAwwl4b"
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "COMPETITION_NAME = \"h-and-m-personalized-fashion-recommendations\"\n",
    "# This is where we want the data to be available for our Spark code\n",
    "LOCAL_DATA_DIR = Path(\"/content/hm_data\")\n",
    "\n",
    "# This is where the persistent data lives in your Google Drive\n",
    "# NOTE: Ensure this path matches where you saved it last time!\n",
    "DRIVE_MOUNT_POINT = \"/content/drive\"\n",
    "DRIVE_PROJECT_PATH = Path(DRIVE_MOUNT_POINT) / \"MyDrive/ScaleStyle_Project/data\"\n",
    "# --- Configuration ---\n",
    "COMPETITION_NAME = \"h-and-m-personalized-fashion-recommendations\"\n",
    "# This is where we want the data to be available for our Spark code\n",
    "LOCAL_DATA_DIR = Path(\"/content/hm_data\")\n",
    "\n",
    "# This is where the persistent data lives in your Google Drive\n",
    "# NOTE: Ensure this path matches where you saved it last time!\n",
    "DRIVE_MOUNT_POINT = \"/content/drive\"\n",
    "DRIVE_PROJECT_PATH = Path(DRIVE_MOUNT_POINT) / \"MyDrive/ScaleStyle_Project/data\"\n",
    "ZIP_FILE_PATH = DRIVE_PROJECT_PATH / f\"{COMPETITION_NAME}.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5qfXgZolxbJ3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qfXgZolxbJ3",
    "outputId": "6566bcd4-047e-45d5-ceab-269e4ec4cfb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Google Drive is already mounted.\n",
      "‚úÖ Found cached dataset in Drive: /content/drive/MyDrive/ScaleStyle_Project/data/h-and-m-personalized-fashion-recommendations.zip\n",
      "‚úÖ Data already extracted at /content/hm_data. Skipping extraction.\n",
      "üìÇ Available files: ['customers.csv', 'articles.csv', 'transactions_train.csv']\n"
     ]
    }
   ],
   "source": [
    "def setup_data_from_drive():\n",
    "    \"\"\"\n",
    "    Mounts Google Drive and prepares the dataset.\n",
    "    1. Mounts Drive.\n",
    "    2. Checks if the ZIP file exists in Drive.\n",
    "    3. Extracts CSVs to the local Colab environment for fast access.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Mount Google Drive\n",
    "    if not os.path.exists(DRIVE_MOUNT_POINT):\n",
    "        print(\"üîπ Mounting Google Drive...\")\n",
    "        drive.mount(DRIVE_MOUNT_POINT)\n",
    "    else:\n",
    "        print(\"‚úÖ Google Drive is already mounted.\")\n",
    "\n",
    "    # 2. Check for the dataset in Drive\n",
    "    if not ZIP_FILE_PATH.exists():\n",
    "        print(f\"‚ùå Error: Dataset not found at {ZIP_FILE_PATH}\")\n",
    "        print(\"   Did you save it to a different folder last time?\")\n",
    "        print(\"   If this is a fresh start, you may need to run the download script once.\")\n",
    "        return\n",
    "\n",
    "    print(f\"‚úÖ Found cached dataset in Drive: {ZIP_FILE_PATH}\")\n",
    "\n",
    "    # 3. Extract to local environment (Faster IO than reading from Drive directly)\n",
    "    # We only extract if the target directory is empty or missing\n",
    "    if not LOCAL_DATA_DIR.exists():\n",
    "        print(\"üîπ Extracting data to local Colab environment (this improves speed)...\")\n",
    "        LOCAL_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Unzip command is faster than Python zipfile\n",
    "        zip_source = str(ZIP_FILE_PATH)\n",
    "        target_dir = str(LOCAL_DATA_DIR)\n",
    "\n",
    "        # Extract specific CSVs to save space/time\n",
    "        !unzip -q -o \"{zip_source}\" \"articles.csv\" \"customers.csv\" \"transactions_train.csv\" -d \"{target_dir}\"\n",
    "\n",
    "        print(f\"‚úÖ Extraction complete! Data is ready at: {LOCAL_DATA_DIR}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Data already extracted at {LOCAL_DATA_DIR}. Skipping extraction.\")\n",
    "\n",
    "    print(f\"üìÇ Available files: {os.listdir(LOCAL_DATA_DIR)}\")\n",
    "\n",
    "\n",
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    setup_data_from_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mR-06AW1xbrJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR-06AW1xbrJ",
    "outputId": "561e193f-0ad5-40f7-cfa4-954771287cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Token retrieved successfully\n",
      "fatal: destination path 'ScaleStyle' already exists and is not an empty directory.\n",
      "\n",
      "üéâ Code downloaded to: ScaleStyle\n",
      "data-pipeline\t    docs\t     inference-service\tREADME.md\n",
      "docker-compose.yml  gateway-service  infrastructure\n"
     ]
    }
   ],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "# 1. Securely retrieve Token (will not be displayed on screen)\n",
    "try:\n",
    "    token = userdata.get(\"GITHUB_TOKEN\")\n",
    "    print(\"‚úÖ Token retrieved successfully\")\n",
    "except Exception:\n",
    "    print(\"‚ùå Token not found. Please check the Secrets panel settings on the left\")\n",
    "\n",
    "# 2. Configure repository information\n",
    "username = \"EthanGaoZhiyuan\"\n",
    "repo = \"ScaleStyle\"\n",
    "\n",
    "# 3. Construct HTTPS URL with Token (Token used for authentication)\n",
    "# Format: https://token@github.com/username/repo.git\n",
    "clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n",
    "\n",
    "# 4. Execute clone command\n",
    "# Use the -b flag to directly clone a specific branch\n",
    "branch = \"feat/phase2-embedding\"\n",
    "!git clone -b {branch} {clone_url}\n",
    "\n",
    "# 5. Verification\n",
    "if os.path.exists(repo):\n",
    "    print(f\"\\nüéâ Code downloaded to: {repo}\")\n",
    "    !ls {repo}\n",
    "else:\n",
    "    print(\"\\n‚ùå Clone failed. Please check Token permissions or repository existence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "V-odJ1owx6Mx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-odJ1owx6Mx",
    "outputId": "2918c472-828c-44b8-dfe3-23d8dfff300e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Current Working Directory: /content/ScaleStyle/data-pipeline\n",
      "‚¨áÔ∏è Installing dependencies from requirements.txt...\n",
      "‚úÖ Added /content/ScaleStyle/data-pipeline to system path.\n",
      "‚úÖ Environment setup complete.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 1. Change directory to the data-pipeline folder to access requirements.txt\n",
    "# This ensures pip installs the exact versions specified in your repo.\n",
    "repo_path = \"/content/ScaleStyle/data-pipeline\"\n",
    "os.chdir(repo_path)\n",
    "\n",
    "print(f\"üìÇ Current Working Directory: {os.getcwd()}\")\n",
    "\n",
    "# 2. Install dependencies\n",
    "# Using -q to keep the output clean.\n",
    "print(\"‚¨áÔ∏è Installing dependencies from requirements.txt...\")\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# 3. Add the project root to system path\n",
    "# This allows Python to recognize 'src' as a module so we can do:\n",
    "# \"from src.feature_engineering import ...\"\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "    print(f\"‚úÖ Added {repo_path} to system path.\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84_TKIas3B4g",
   "metadata": {
    "id": "84_TKIas3B4g"
   },
   "source": [
    "# GENERATE EMBEDDINGS WITH BAAI/BGE-LARGE (INDUSTRIAL STANDARD)\n",
    "\n",
    "**MODEL SELECTION RATIONALE:**\n",
    "I switched to **\"BAAI/bge-large-en-v1.5\"** for the following reasons, targeting a more production-ready architecture:\n",
    "\n",
    "1.  **Industrial Standard (Efficiency vs. Performance)**: Unlike the 7B parameter Qwen2, BGE-Large has only **~335M parameters**. This represents the \"Gold Standard\" in the industry, allowing for ultra-low latency inference while maintaining top-tier retrieval quality.\n",
    "2.  **MTEB Leaderboard**: It consistently ranks high on the Massive Text Embedding Benchmark (MTEB), specifically for English retrieval tasks.\n",
    "3.  **Encoder Architecture (BERT-based)**: This uses a standard BERT-like architecture with a **512 token limit**, which is sufficient for product names and descriptions. It uses `[CLS]` pooling, which is structurally more suitable for vector search than Decoder-based LLMs.\n",
    "4.  **Hardware Optimization**: Due to its smaller size, we can significantly increase the **Batch Size (e.g., to 256)**, making the data processing pipeline 10x faster than before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "CJwl69l36RpA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJwl69l36RpA",
    "outputId": "fe73ca3e-3942-4ba7-91db-6f748278c911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mkCKCjwNyWiq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "8861a04f29704cb7b6eccbb94bab0eea",
      "a6098f1236ad410083c15416817f7f00",
      "ed051ee1ba044f96a19d62490b024575",
      "ec93a4440d37440181308b9d8465ddbb",
      "eda57f9329e648da9ac496c1f91712de",
      "e6bfea8e4dca4375b51070187d13f4d8",
      "f603e06ef98647c2822ad710c6b854b0",
      "c8833a7c473b4953aa64c7b1f961250b",
      "3caf0903eab54d948dc0faa370b4f1d8",
      "48bacf48fdc341549dc091e820ddcb7d",
      "c5b91c2b94a54fd0a8cb4cb23fa841bf"
     ]
    },
    "id": "mkCKCjwNyWiq",
    "outputId": "9cf9ebe1-ee38-4612-8e13-fceab5988b3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing SOTA model: BAAI/bge-large-en-v1.5 on GPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading article data from: /content/drive/MyDrive/ScaleStyle_Project/data/processed/articles_parquet\n",
      "transactions rows: 27306439 cols: ['article_id', 'price']\n",
      "Total items to process: 105126\n",
      "Start Batch Inference with Qwen2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8861a04f29704cb7b6eccbb94bab0eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/411 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to: /content/drive/MyDrive/ScaleStyle_Project/data/processed/article_embeddings_bge_v2.parquet\n",
      "CRITICAL NOTE: The vector dimension is 1024.\n",
      "(Please ensure your Milvus Collection is created with dim=1024)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_NAME = \"BAAI/bge-large-en-v1.5\"\n",
    "BATCH_SIZE = 256\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "# Input/Output Paths (Google Drive)\n",
    "INPUT_PATH = \"/content/drive/MyDrive/ScaleStyle_Project/data/processed/articles_parquet\"\n",
    "TRANSACTIONS_PATH = \"/content/drive/MyDrive/ScaleStyle_Project/data/processed/transactions_parquet\"\n",
    "OUTPUT_PATH = \"/content/drive/MyDrive/ScaleStyle_Project/data/processed/article_embeddings_bge_v2.parquet\"\n",
    "\n",
    "# def last_token_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     Extracts the embedding from the last token.\n",
    "#     For Causal LLMs (like Qwen) used as embedding models,\n",
    "#     pooling the last token (EOS) is the standard practice, unlike BERT which uses [CLS].\n",
    "#     \"\"\"\n",
    "#     left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "#     if left_padding:\n",
    "#         return last_hidden_states[:, -1]\n",
    "#     else:\n",
    "#         sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "#         batch_size = last_hidden_states.shape[0]\n",
    "#         # Gather the hidden state corresponding to the last real token\n",
    "#         return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "def cls_pooling(model_output):\n",
    "    \"\"\"\n",
    "    BGE/BERT Standard Pooling: Take the first token ([CLS])\n",
    "    \"\"\"\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Initializing SOTA model: {MODEL_NAME} on GPU...\")\n",
    "\n",
    "    # 1. Load Model & Tokenizer\n",
    "    # Note: 'trust_remote_code=True' is strictly required for Qwen2 custom architecture.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        trust_remote_code=False,\n",
    "        torch_dtype=torch.float16,  # Use FP16 to save VRAM and accelerate on A100\n",
    "        device_map=\"cuda\"\n",
    "    )\n",
    "\n",
    "    # 2. Load Data\n",
    "    print(f\"Reading article data from: {INPUT_PATH}\")\n",
    "    df_tx = pd.read_parquet(TRANSACTIONS_PATH, columns=[\"article_id\", \"price\"])\n",
    "    print(\"transactions rows:\", len(df_tx), \"cols:\", df_tx.columns.tolist())\n",
    "\n",
    "\n",
    "    df_price = (\n",
    "        df_tx.groupby(\"article_id\", as_index=False)[\"price\"]\n",
    "        .mean()\n",
    "        .rename(columns={\"price\": \"price\"})\n",
    "    )\n",
    "\n",
    "    df_articles = pd.read_parquet(INPUT_PATH)\n",
    "\n",
    "    df_articles = df_articles.merge(df_price, on=\"article_id\", how=\"left\")\n",
    "\n",
    "    # 3. Construct Input Text\n",
    "    # Since I'm embedding documents (products), I use the raw text.\n",
    "    # Instruction prompts (e.g., \"Given a query...\") are only needed during the retrieval phase.\n",
    "\n",
    "    # Preprocessing\n",
    "    df_articles['prod_name'] = df_articles['prod_name'].fillna(\"Unknown Product\")\n",
    "    df_articles['detail_desc'] = df_articles['detail_desc'].fillna(\"\")\n",
    "    df_articles['colour_group_name'] = df_articles['colour_group_name'].fillna(\"\")\n",
    "\n",
    "    # Concatenate fields to form a rich semantic representation\n",
    "    raw_texts = (\n",
    "        \"Product: \" + df_articles['prod_name'] + \". \" +\n",
    "        \"Description: \" + df_articles['detail_desc'] + \". \" +\n",
    "        \"Attributes: \" + df_articles['colour_group_name']\n",
    "    ).tolist()\n",
    "\n",
    "    print(f\"Total items to process: {len(raw_texts)}\")\n",
    "\n",
    "    # 4. Batch Inference Loop\n",
    "    all_embeddings = []\n",
    "\n",
    "    print(\"Start Batch Inference with Qwen2...\")\n",
    "    for i in tqdm(range(0, len(raw_texts), BATCH_SIZE)):\n",
    "        batch_texts = raw_texts[i : i + BATCH_SIZE]\n",
    "\n",
    "        # Tokenize inputs\n",
    "        batch_dict = tokenizer(\n",
    "            batch_texts,\n",
    "            max_length=MAX_LENGTH,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_dict)\n",
    "\n",
    "            # Extracting\n",
    "            embeddings = cls_pooling(outputs)\n",
    "\n",
    "            # Normalizing\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "\n",
    "            # Move to CPU to save GPU memory\n",
    "            all_embeddings.append(embeddings.float().cpu().numpy())\n",
    "\n",
    "    # 5. Save Results\n",
    "    final_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "    # Save as a list column in the DataFrame\n",
    "    df_articles['embedding'] = list(final_embeddings)\n",
    "\n",
    "    # Keep only ID and Embedding columns for Milvus ingestion\n",
    "    output_df = df_articles[['article_id', 'embedding', 'price', 'colour_group_name']]\n",
    "    output_df.to_parquet(OUTPUT_PATH)\n",
    "\n",
    "    print(f\"Embeddings saved to: {OUTPUT_PATH}\")\n",
    "    print(f\"CRITICAL NOTE: The vector dimension is {final_embeddings.shape[1]}.\")\n",
    "    print(f\"(Please ensure your Milvus Collection is created with dim={final_embeddings.shape[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "_T37W1nhSAVl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_T37W1nhSAVl",
    "outputId": "d2a1cd7f-53bb-4a75-a100-b6c8f7dc7af8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b7e0a6be-4719-4d6f-94e4-5e39748e001d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>embedding</th>\n",
       "      <th>price</th>\n",
       "      <th>colour_group_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>[0.009101868, -0.031799316, 0.010383606, 0.007...</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>[0.004814148, -0.022735596, 0.012435913, -0.00...</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108775051</td>\n",
       "      <td>[-0.0036678314, -0.016036987, 0.009941101, -0....</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>Off White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110065001</td>\n",
       "      <td>[-0.021087646, -0.050109863, -0.0077171326, -0...</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110065002</td>\n",
       "      <td>[-0.022323608, -0.0463562, -0.010498047, -0.01...</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7e0a6be-4719-4d6f-94e4-5e39748e001d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b7e0a6be-4719-4d6f-94e4-5e39748e001d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b7e0a6be-4719-4d6f-94e4-5e39748e001d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   article_id                                          embedding     price  \\\n",
       "0   108775015  [0.009101868, -0.031799316, 0.010383606, 0.007...  0.008133   \n",
       "1   108775044  [0.004814148, -0.022735596, 0.012435913, -0.00...  0.008108   \n",
       "2   108775051  [-0.0036678314, -0.016036987, 0.009941101, -0....  0.004993   \n",
       "3   110065001  [-0.021087646, -0.050109863, -0.0077171326, -0...  0.019989   \n",
       "4   110065002  [-0.022323608, -0.0463562, -0.010498047, -0.01...  0.018037   \n",
       "\n",
       "  colour_group_name  \n",
       "0             Black  \n",
       "1             White  \n",
       "2         Off White  \n",
       "3             Black  \n",
       "4             White  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = pd.read_parquet(OUTPUT_PATH)\n",
    "_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2vcOoqCsSunq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "2vcOoqCsSunq",
    "outputId": "b6c09830-a178-48eb-da55-13363b9f56ae"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 365406406.1877104,\n        \"min\": 105126.0,\n        \"max\": 959461001.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          698796227.1491925,\n          702778002.5,\n          105126.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36815.83616685905,\n        \"min\": 0.000423728813559322,\n        \"max\": 104131.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.02869141974080683,\n          0.022864406779661017,\n          104131.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f2dee8c3-1b2d-499e-b94d-905940157d16\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.051260e+05</td>\n",
       "      <td>104131.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.987962e+08</td>\n",
       "      <td>0.028691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.284961e+08</td>\n",
       "      <td>0.025727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.087750e+08</td>\n",
       "      <td>0.000424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.173330e+08</td>\n",
       "      <td>0.014390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.027780e+08</td>\n",
       "      <td>0.022864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.969778e+08</td>\n",
       "      <td>0.033690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.594610e+08</td>\n",
       "      <td>0.506780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2dee8c3-1b2d-499e-b94d-905940157d16')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f2dee8c3-1b2d-499e-b94d-905940157d16 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f2dee8c3-1b2d-499e-b94d-905940157d16');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "         article_id          price\n",
       "count  1.051260e+05  104131.000000\n",
       "mean   6.987962e+08       0.028691\n",
       "std    1.284961e+08       0.025727\n",
       "min    1.087750e+08       0.000424\n",
       "25%    6.173330e+08       0.014390\n",
       "50%    7.027780e+08       0.022864\n",
       "75%    7.969778e+08       0.033690\n",
       "max    9.594610e+08       0.506780"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5OIUPm2KSxPi",
   "metadata": {
    "id": "5OIUPm2KSxPi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3caf0903eab54d948dc0faa370b4f1d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48bacf48fdc341549dc091e820ddcb7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8861a04f29704cb7b6eccbb94bab0eea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a6098f1236ad410083c15416817f7f00",
       "IPY_MODEL_ed051ee1ba044f96a19d62490b024575",
       "IPY_MODEL_ec93a4440d37440181308b9d8465ddbb"
      ],
      "layout": "IPY_MODEL_eda57f9329e648da9ac496c1f91712de"
     }
    },
    "a6098f1236ad410083c15416817f7f00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6bfea8e4dca4375b51070187d13f4d8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f603e06ef98647c2822ad710c6b854b0",
      "value": "100%"
     }
    },
    "c5b91c2b94a54fd0a8cb4cb23fa841bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8833a7c473b4953aa64c7b1f961250b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e6bfea8e4dca4375b51070187d13f4d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec93a4440d37440181308b9d8465ddbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48bacf48fdc341549dc091e820ddcb7d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c5b91c2b94a54fd0a8cb4cb23fa841bf",
      "value": "‚Äá411/411‚Äá[00:58&lt;00:00,‚Äá‚Äá7.47it/s]"
     }
    },
    "ed051ee1ba044f96a19d62490b024575": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8833a7c473b4953aa64c7b1f961250b",
      "max": 411,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3caf0903eab54d948dc0faa370b4f1d8",
      "value": 411
     }
    },
    "eda57f9329e648da9ac496c1f91712de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f603e06ef98647c2822ad710c6b854b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}