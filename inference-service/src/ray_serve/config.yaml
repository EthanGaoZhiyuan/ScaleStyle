# src/ray_serve/config.yaml

proxy_location: EveryNode

http_options:
  host: 0.0.0.0
  port: 8000

applications:
  - name: scale_style_app
    import_path: src.ray_serve.deployments.ingress:ingress_app
    route_prefix: /
    runtime_env:
      env_vars:
        # Redis configuration
        REDIS_HOST: "localhost"
        REDIS_PORT: "6379"
        POPULARITY_KEY: "global:popular"
        
        # Milvus configuration
        MILVUS_HOST: "localhost"
        MILVUS_PORT: "19530"
        MILVUS_COLLECTION: "scale_style_bge_v2"
        
        # Embedding configuration
        EMBEDDING_MODEL: "BAAI/bge-large-en-v1.5"
        EMBEDDING_MAX_LEN: "512"
        EMBEDDING_NUM_CPUS: "2"
        EMBEDDING_NUM_GPUS: "0"
        EMBEDDING_QUERY_PREFIX: "Represent this sentence for searching relevant passages:"
        EMBEDDING_TIMEOUT_MS: "1200"
        
        # Retrieval configuration
        RECALL_K: "100"
        RETRIEVAL_TIMEOUT_MS: "800"
        
        # Reranker configuration
        RERANKER_ENABLED: "1"
        RERANKER_MODEL: "BAAI/bge-reranker-base"
        RERANKER_DEVICE: "cpu"
        RERANKER_BATCH_SIZE: "16"
        RERANKER_MAX_DOCS: "100"
        RERANKER_MODE: "cross-encoder"
        RERANKER_TIMEOUT_MS: "1200"
        RERANKER_WARMUP: "1"
        
        # A/B testing configuration
        BASE_FLOW_MODE: "vector"  # Options: vector, popularity
        
        # Generation configuration
        GENERATION_ENABLED: "0"  # Default off until model is loaded
        GENERATION_TIMEOUT_MS: "600"
        GENERATION_FLOW: "smart"  # Options: smart (only SEARCH), all (always)
        GENERATION_MODEL: "Qwen/Qwen2-1.5B-Instruct"
        GENERATION_DEVICE: "auto"  # auto, cpu, cuda, mps
        GENERATION_MAX_NEW_TOKENS: "48"
        GENERATION_TEMPERATURE: "0.2"
        GENERATION_TOP_P: "0.9"
        GENERATION_DO_SAMPLE: "0"
        GENERATION_DTYPE: "float16"
        GENERATION_WARMUP: "1"
        
        # Ray/HuggingFace configuration
        RAY_SERVE_RUN_SYNC_IN_THREADPOOL: "1"
        TOKENIZERS_PARALLELISM: "false"
        HF_HOME: "/tmp/hf"  # Model cache directory
        HF_HUB_DISABLE_TELEMETRY: "1"
        TRANSFORMERS_CACHE: "/tmp/hf/transformers"