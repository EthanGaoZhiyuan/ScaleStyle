---
# Optional: Inference HPA (if not using KubeRay autoscaler)
# This HPA can be used if you deploy inference with standard Deployment (30-inference.yaml)
# DO NOT use this with RayService (80-raycluster.yaml) as Ray has its own autoscaling
#
# To enable:
#   kubectl apply -f infrastructure/k8s/70-inference-hpa.optional.yaml
#
# To disable:
#   kubectl delete hpa inference-hpa -n scalestyle

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: inference-hpa
  namespace: scalestyle
  labels:
    app: scalestyle
    component: inference-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: inference
  
  # Scaling boundaries
  minReplicas: 1
  maxReplicas: 5
  
  # Metrics for scaling decisions
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # Scale when avg CPU > 70%
  
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80  # Scale when avg memory > 80%
  
  # Scaling behavior
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60  # Wait 1min before scaling up
      policies:
      - type: Pods
        value: 1  # Add 1 pod at a time
        periodSeconds: 60
      selectPolicy: Max
    
    scaleDown:
      stabilizationWindowSeconds: 300  # Wait 5min before scaling down
      policies:
      - type: Pods
        value: 1  # Remove 1 pod at a time
        periodSeconds: 120
      selectPolicy: Min
